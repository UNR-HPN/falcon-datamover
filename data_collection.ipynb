{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import log_file_reader\n",
    "import dir_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_log_files_directory = \"/home/marifuzzaman/Downloads/NeuralNets/AdaptiveGridFTPClient/logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({})\n",
    "\n",
    "dir_paths = dir_filter.get_dir_paths(path_to_log_files_directory)\n",
    "        \n",
    "for i, path in enumerate(dir_paths):\n",
    "    path = os.path.join(path_to_log_files_directory, path)\n",
    "    dir_paths[i] = path\n",
    "        \n",
    "for dir_path in dir_paths:\n",
    "    if 'freq' in dir_path.split('/'):\n",
    "        continue\n",
    "           \n",
    "    files = [f for f in os.listdir(dir_path)]\n",
    "            \n",
    "    for file in files:\n",
    "        try:\n",
    "            if \".csv\" in file:\n",
    "                continue\n",
    "                    \n",
    "            file_path = os.path.join(dir_path, file)\n",
    "            seconds, throughputs = log_file_reader.get_all_data(file_path)\n",
    "                \n",
    "            if len(throughputs) == 0 or sum(throughputs) == 0:\n",
    "                continue\n",
    "            \n",
    "            if 'pronghorn' in file_path:\n",
    "                net_name = 'pronghorn'\n",
    "            elif 'dtns' in file_path:\n",
    "                net_name = 'dtns'\n",
    "            elif 'esnet' in file_path:\n",
    "                net_name = 'esnet'\n",
    "            elif 'comet' in file_path or 'sc' in file_path:\n",
    "                net_name = 'xsede'\n",
    "            else:\n",
    "                net_name = np.nan\n",
    "            \n",
    "            data = {\n",
    "                \"file_name\": [file],\n",
    "                \"network_name\": [net_name]\n",
    "            }\n",
    "\n",
    "            for i in range(len(throughputs)):\n",
    "                key = 'p' + str(i+1)\n",
    "                data[key] = [throughputs[i]]\n",
    "\n",
    "            data['mean_throughput'] = [np.mean(throughputs)]\n",
    "            data['median_throughput'] = [np.median(throughputs)]\n",
    "            data['stdv_throughput'] = [np.std(throughputs)]\n",
    "                    \n",
    "            temp_df = pd.DataFrame(data)\n",
    "            df = df.append(temp_df, ignore_index=True, sort=False)\n",
    "        except Exception as e:\n",
    "            file_path = os.path.join(dir_path, file)\n",
    "            print(\"{0}: {1}\".format(file_path, e))\n",
    "            \n",
    "df.to_csv(\"network_data_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
